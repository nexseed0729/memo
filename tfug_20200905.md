# ベイズ分科会

- https://tfug-tokyo.connpass.com/event/184984/
- https://www.youtube.com/watch?v=7rBI11Rze2c

## イントロ
- こんな悩みないか？
    - データが少ない
    - 教師データがない
    - 解釈性が低い
    - 本番運用後に精度が下がる
- 解釈性と扱う対象の複雑さという俗説的なトレードオフを断ち切る。どっちも両立したい
- モデルを選んでチューニングじゃなくて、課題ベースのソリューション設計
- ベイズモデルとは何か？
    - データに対して数学的な仮定を与えることでデータから何かしら有用な結果を引き出す
- ベイズモデリングでできることは？
    - 不確実性を伴った予測
        - ベイズモデルだと、予測において、「縦方向に幅」が出る。将来の値はコレっていう一点で示すんでなく、分布感を持って示せる
    - 課題に合わせた柔軟な解析
        - シンプルな課題から複雑な課題まで柔軟に解析できる。
    - 線形回帰モデル（普通に線を引いて予測する）って、入力値がないって仮定しただけで PCA とほぼ同じ。線形回帰モデルと PCA ってほぼ違いがない。つまり一見異なるモデルでもシームレスにつながっている。
    - オーバーフィットの回避
- 確率分布（確率モデル）
- 確率計算（推論計算）
    - 基本的には周辺確率と条件付き確率の 2 式をいかに効率よく計算できるかがベイズ統計の技術的な関心。
    - 条件付き確率について・・・p(x | y) の y がデータ（観測されているデータ）。x は観測されていない変数
- 用語に関する注意点
    - 学習・推論・予測（ベイズモデリングでは大量データの学習および新しいデータに対する予測をまとめて推論という。ベイズの理論的には学習と予測は区別する必要がない）
    - モデル、モデリング: データに対して置く数理的な仮定をモデルと呼ぶ。
人手でモデルを設計するので、データを与える前からモデルは存在する。
    - アルゴリズム:条件付き分布を数値的に解析する計算手法のことを指す。（例: MCMC、変分推論法）
- 普通の機械学習との違いは？
    - ツールボックスアプローチ（一般に使われているアプローチ）
        - 取り組んでいる問題に使えそうな既存アルゴリズムを探してくる。
        - 前処理や特徴量抽出などを使って、既存アルゴリズムが動作するように「合わせこむ」
    - モデリングアプローチ
        - データや課題に応じた数理モデルをデザインする。
- ベイズモデリングと解析業務
    - 状況に合わせたモデル改善
    - 一貫したアプローチ
    - 「理解」を主軸にした開発
    - モデルの改善作業とデータの理解が必ず同じ方向を向いてるというのがベイズモデリングのいいところ。

- ベイズモデリングの理想と現状（左辺は現状。右辺は理想）
    - 数理的知識が要求される。。 -> モデルの設計が直感的に行えると理想
    - 実装までに大変な時間と労力がかかる -> モデルを設計したあとは、計算アルゴリズムはツールで自動的に生成される。これにより、分析者はモデル設計や評価に集中できる。
    - そのまま使おうと思うと計算時間が膨大になる -> ツールが自動的に高効率な並列化計算を行う。ようになると理想

- 解決策：確率的プログラミング言語の活用
    - PPL とは
        - Probabilistic programming language (PPL)
        - モデリング作業を簡略化するためのソフトウェア
        - 多くは Python や R のライブラリとして利用可能
    - 手計算を排除
        - コーディングによってモデルを記述する。データシミュレーションによって挙動を確認しながらモデル設計できる。
        - 推論アルゴリズムは自動微分によって自動的に導出される。
    - 解析サイクルを効率化
        - モデル設計の直感か、推論計算の自動導出、GPU/TPU による計算高速化により、データ解析サイクルは圧倒的に効率化
        - 解析者は課題理解・モデルの試行錯誤に多くの時間を費やすことができる。
    - tensorflow.probability

- ベイズモデリングでは、確率モデルと呼ばれるデータに対する数理的な仮定を設計し、推論計算によって有益な情報を引き出す
- 確率的プログラミング言語（PPL）の進化によって、ベイズm度絵リングの活用のハードルは年々下がってきている
- PPL が特に便利なのは次の理由
    - コーディング＆データシミュレーションによる直感的なモデル設計
    - 自動微分などの技術に基づく効率的な推論計算アルゴリズムの自動導出
- 須山さんは普段は Julia で書いているらしい

Q. データの生成過程に仮定をうまく置くというのがベイズで、その過程の置き方に知識が必要で大変というのがベイズモデリングのデメリットではないか？
A. 他のMLでも背後は一緒。データの生成仮定を仮定するということは（気づいていないだけで）必ずやっているはず。データの生成過程が読みづらいものはベイズだろうが他のMLだろうが難しい。
仮定できないなら仮定できないなりに、ガウス過程とか仮定のゆるいもの（過程を置かないもの）を使えばいい。

Q. モデルの良し悪しはどう判断する？
A. モデルの良し悪しの判断は、DL と同じようにクロスバリデーションを行うことが第一義。
あとは周辺尤度を計算したり WAIC を計算したりなど。

Q. Julia ではなんらかの PPL を利用しているのか？
A. Julia だと計算が早い。C++ で一生懸命頑張るのと一緒くらい。PyMC や Stan、Tensorflow probability などの PPL を使うことも多いけど、Julia だとスクラッチで実装することが多い。

Q. 画像認識や自然言語のようなタスクにも応用できる？　その場合は深層学習は組み合わせることになる？
A. 「ベイズ深層学習」という本にいろいろ載っている。画像処理でも、ドライブレコーダーから奥行きを推定するという問題があるとして、奥行きを 10.2 m とかピタッと予測するのではなく、8m から 12m、みたいな感じで分布的に予測するというのがベイズと深層学習を使うとできるようになる。

Q. ベイズモデリングでオーバーフィットがないと言われるのはなぜ？
A. そもそも fit がない。最小二乗法モデルが誤差を減らそうとするからオーバーフィットが起こる。
条件付き確率の式をみると、最小化（つまり fit）がない。事後確率求めるだけ。overfitting が起こらないのは fit をしようとしてないから。やみくもなパラメータ最適化なんて一切やらない。

----
## PPL の現状 (by Hello Cybanetics)

### なぜ　PPL を利用するのか
- データ分析の大まかな流れ
    - 仮説を構築
    - データ収集
    - データと現象のモデリング
    - 推論の実行
    - 説明、予測実施
- このうちの「データと現象のモデリング」「推論の実行」を助けてもらうため。

### モデリングと推論実行の概要
1. 予測したい変数を取り巻く確率変数の関係性を整理
    - p(X,Y,W) = p(X)p(W)p(Y|X, W)
1. 各変数、パラメータに確率分布を設定（具体的な同時分布が形成）
1. 観測データによるパラメータの事後分布を計算（紙とペン or MCMC or 変分推論）
-> この確率変数を設定してモデルを作りますという領域を PPL が対応してくれる

### 様々な PPL
- 近年は深層学習ライブラリベースの GPU 対応 PPL が出てきている
    - TennsoFlow Probability (Tensorflow)
    - Pyro (PyTorch)
    - NumPyro
    - PyMC4
    - Stan

- 可視化ライブラリ ArviZ
    - 共通のデータ構造である InferenceData を提供
    - Python, Julia から利用可能
    - TFP, PyMC, Pyro, Pystan 対応

### ざっくりとした雰囲気
粒度小
 TF Probability （カスタマイズ性が高い）
 Pyro / NumPyro
 Stan
 PyMC （推論まわりとか任せっきりにできる）
粒度大

+ ArviZ

### 実行時間ベンチマーク
- https://luiarhur.github.io/TuringBnpBenchmarks/

### 新しいPPLも十分に実用的速度
- 基本的に Stan は早い
- Compile 時間を含めると New PPLs は速い

### 使いやすさはどうか？

```
1. 各変数、パラメータに確率分布を設定（具体的な同時分布が形成）  
1. 観測データによるパラメータの事後分布を計算（紙とペン or MCMC or 変分推論）
```

の部分のコードを比較してみよう。
- Stan
    - Stan(C++) を Python や R から叩く。Stan にやらせたいことは Stan に書ききる
- TFP
    - サンプラ周りのコードが少し重い。推論対象のパラメタもユーザが管理。
    - 分散未知のモデルではサンプラ周りのコードがだいぶ重くなる。
- PyMC4
    - モデルを推論関数に渡すだけ（パラメタ管理等を任せられる）
    - 別途モデルを解釈できる関数で予測モデルなどを構築可能
- Pyro
    - モデルを推論クラスに渡す（パラメタ管理等を任せられる）
    - 別途モデルを解釈できる関数・クラスで予測モデルなどを構築可能

- Tensorflow Probability は一段低いところから書く（細かいことを書ける/書かなくてはいけない）
- Pyro のインターフェースが気に入っている
- PyMC4 は完成すれば第一候補（PyMC4 で弄れない時にしかたなく TFP を使う感じ）。ただ、今現在の本格利用はまだ早い。

### クラスタリングの例
- 3 つの異なる多変量正規分布からランダムにデータを取得
- 同時分布の記述をするのがモデリングの 1st step
    - ここの、コードへの落とし込みが Pyro だとやりやすい
- 事後分布の推論
    - 推論はたったの 3 行
    - 推論するパラメタは自動判定
    - 離散パラメタは自動で周辺化
    - summary() メソッドでサマリーもすぐ見れる
- arviz を使えば可視化も楽

### 最後に
- DL がライブラリの整備で興隆した
- Julia 言語でも Turing.jl や Gen.jl 等が開発中
- 今後 PPL の整備で、DL が流行ったみたいに確率モデリングも盛り上がるのではないか
- TFP と PyMC4 が今後確率モデリングをブーストするはず
- 今は個人的に Pyro が使いやすいが今後の整備に注目

---
## TFP の基礎
- https://colab.research.google.com/drive/1FKBlG5Y0i6dzO4gWFMYvQgv7z1ta6Ot5?usp=sharing

### Distribution モジュール
- 数多くの確率分布が実装されている。
- 線形ガウス状態空間モデルなどの複雑なモデルも。

### Bijector モジュール
- bijector は確率分布の変数変換に用いられる。
- 確率 X を Y = g(X) により変換する、というのをやってくれる。

### TFP における shape について
- TFP を用いてモデリングする際に混乱しやすい
- TFP には以下 3 つの shape の概念がある
    - Batch shape: 異なる複数の確率分布をまとめて取り扱う際に使われる。
    - Event shape: 1 つのサンプルに含まれる次元の数。
    - Sample shape: 試行の回数（たぶん？）

### JointDistribution
- 同時分布の設計に使うクラス。
- JointDistribution にはサブクラスがいくつかある。

Q. yield を使った書き方は「決まった書き方」的なものか？
A. 決まった書き方と捉えてもらって問題ない。dict を使った書き方など他のやり方もあるが、いずれにしても定型的な書き方。

## 深層生成モデルと世界モデル、深層生成モデルライブラリ Pixyz について（鈴木雅大）

### 自己紹介
興味：汎用的な人工知能の実現において、確率モデルでどう実現できるか？

### 目次
- 深層生成モデル
- 世界モデルと深層生成モデル
- Pixyz
- まとめ

### 深層生成モデル
- 深層学習の研究分野では、深層生成モデルの研究が進んでいる。
- 生成系の他に、異常検知、反響しあり学習、表現学習など

### 確率的生成モデル
- 観測されたデータが未知のデータ分布から生成されていると過程し、その生成過程を確率分布によってモデル化する枠組み
    - データとして観測される観測変数の他に、その背景にある確率変数として潜在変数も仮定することが多い
- データがどのようにできているか？　を明示的に設計することができ、もでうからデータを生成（シミュレーション）することができる

### 生成モデルの学習
- 目標：生成モデルがデータ分布を近似するようにしたい

### 生成モデルでできること
- 生成
- 密度推定
- 欠損値保管、ノイズ除去

### 生成モデルにおける推論
- 推論
    - 潜在変数が与えられたもとで、任意の確率変数（潜在変数）の事後分布を求める
    - 潜在変数を持つ生成もでrつにおけるじゅうよう　な概念（結果から原因を探る）
- 一般のモデルでは、推論は計算困難なことが多い

本発表では、潜在変数の事後分布を求めること（推論）とモデルのパラメータ値を最適化すること（推定、学習）を区別する。

### 深層生成モデル
- 観測変数が複雑な場合、単純な確率分布では直接表現できない。
    - おt句に観測変数がベクトルで、次元間の依存関係が非線形な場合
    - 従来の生成モデルは、複雑な観測データを緒k末つ生成することは意図していなかた（e.g. トピックモデル）
->  複雑な関係性を表すには？ -> DNN

- 深層生成モデル
    - 確率分布を DNN で表現した生成モデル
    - モデルパラメータは勾配情報に基づき学習

### 深層生成モデルの種類
- VAE や GAN の他に、自己回帰モデル、フローベース、拡散モデル、スコアベース、エネルギーベースなどいろいろある。

### Variational Autoencoder
- 潜在変数モデルの確率分布を DNN で表現する
- これが出たのは 2013 年くらい。
- 潜在変数に対してランダムな値を入れてあげて、本物っぽいデータ（本物っぽい手書き数字や顔写真など）を生成できる

### VAE と表現学習
- VAE では、再構成だけでなく表現 z も学習しているとみなせる。
- 深層生成モデルにおいては、表現学習は推論と等価
- VAE は表現学習手法として優れた手法

### Disentangled representation
- データは独立に変化する要素から生成されているという仮定
    - 例：物体のむき、光源の状態
    - 利点：
        - 人間が解釈しやすい表現
        - 様々なタスクに転用できる可能性
    - 推論モデルへの正則化によって disentangle な表現を獲得可能

### 条件付き深層生成モデル
- 観測変数 y（x と異なる情報）で条件づけた深層生成モデル
    - y から x への生成過程を表現

### 世界モデルと深層生成モデル
#### 世界モデル
- 人間は世界のあらゆるものを近くできるわけではない
    - 脳に入ってくる情報は非常に限られている
    - したがって脳の内部では、限られた情報から現実世界をモデル化している
- 世界モデル
    - 外界からの限られた観測を元に、世界の構造を近似するように学習するモデル
    - 観測から要因を推論し、推論した要因から未来や未知のことを予測する

- 脳内では、外界からの情報を空間的・時間的な表現に圧縮している

#### 世界モデルによる予測
- 学習した世界モデルによって未来をシミュレーションしている
- 例：バットを振ってボールに当てる

### 深層生成モデルを用いた世界モデル
- 空間的な圧縮に VAE を使っている。時間的な遷移のモデルに MDN-RNN を使っている。
- 世界モデル内での強化学習
    - 学習した世界モデルの中で強化学習を行う

### 複雑な環境での世界モデル
- Generative Query Network (GQN)
    - ある複数の視点における画像を元に、別の視点の画像を予測する世界モデル
    - 条件付き深層生成モデルの利用

### 時系列情報からの世界モデルの獲得
- エージェントの視点と行動から、世界の普遍的な構造を学習
    - 深層状態空間モデルの学習と強化学習を同時に行う
- 状態でどのような表現が獲得されているかを確認

### 推論としての方策最適化
- 強化学習における方策の最適化も、確率モデルにおける推論とみなすことができる
- Control as Inference

### 世界モデルとマルチモーダル学習

### マルチモーダルVAE
- Joint Multimodal VAE (JMVAE)
     -画像と文書を異なるモダリティと考え、それらの情報を統合した共有表現を推論するVAE
     - 単一モダリティ空も推論するために、それぞれの推論モデルを用意して KL 最小化で近づける
- Neuto-SERKET
    - 深層生成モデルを含む確率的生成モデルによるマルチモーダル認知アーキテクチャの提案
    - VE + GMM + LDA + ASR の例（数字の画像（MNIST）と音声から学習）

### Pixyz
### 深層生成モデルと確率プログラミング言語
- 深層学習の実装のためのライブラリ

- 既存の確率プログラミング言語では、近年の複雑な深層生成モデルを実装することが困難

### Pixyz
- 深層生成モデルに特化した確率プログラミングライブラリ
    - 複雑な深層生成モデルを完結に実装できることが特徴
    - PyTorchベース

### Pixyz の実装例
- DNN によって確率分布を定義（パラメータ化）する
- Pixyz では、分布動詞の掛け算で確率モデルの同時分布を構成できる。

## 時系列データと確率的プログラミング（yutakashino）
https://www.slideshare.net/yutakashino/tfpsts

### 今日の目的
- tfp は時系列の扱い: 仕組みと実装を見る
    - 構造時系列
    - カルマンフィルタ
    - VI/MCMC
- CO2 濃度時系列を例にとる

### tfp.sts
- Structural Time Series
- カルマンフィルタで時系列を構造的に解く

tfp.vi で変分推定をする
- 代替事後分布（サロゲート・ポステリア）を自動的に求めてくれたりする

### 状態空間モデルの時系列
- 状態
- 観測
- 分散と誤差をモデルに含める
- 一期先推定

### カルマンフィルタ
- 線形ガウス状態空間モデル
- カルマンサイクル
- おすすめ→https://www.youtube.com/playlist?list=PLX2gX-ftPVXU3oUFNATxGXY90AULiqnWT

## 変分近似推定
- KL距離を最小にする q(θ) を求める

### TFP の MCMC: sts.fit_with_hmc
- CO2 濃度推定という簡単な問題でも時間かかる。。

### tfp.sts: pros
- tfp.distribtions
- colaboratory
- @tf.function(experimental_compile=true)
- Bijector API の存在
- API が論文・教科書の素直な実装
- BigQuery との連携

### tfp.sts: cons
- MCMC が激遅い
- バグが多すぎ。まともに動作しないこと多め
- Traceback が意味不明
- API ごとに Tensor shape がややこしい
- API が統一した観点で整理されていない
- 確率モデリング以外にやることが多すぎ
    - PyMC4, edword2 が使えるようになって…
- プロダクションでは使うのは困難

- facebook の Prophet （時系列予測OSS）はめっちゃ速い。

-----

## 座談会
### データ分析や機械学習は自動化されるのか？
- 切り分けて、「DX まで行かせる」というところが大変。紙をなくすところからなので。

鈴木さん「松尾研のイメージ「DLにとりあえず突っ込めばいいと思われてるかもしれないが、人間の知識があるとしたらそれもちゃんと考慮した方がいいと思ってる。人間の知識・知見を入れつつデータを活用するという両面から世界モデルも考えていけばいい」

須山さん「データって現実を切ってしまう。切り口は痛々しい。データだけだと正しいものが抽出できないことも往々にしてあり、人間の知見を入れることが必要」

かしのさん「世界モデル、エージェントが自動的に獲得していくとなると、表現学習もそうだが、強化学習でもって、囲碁みたいな形で、機械がなんでもかんでも知識を獲得していくってために作ってるの？」

鈴木「データから世界のシミュレータを獲得して、そのうえでいろいろ行動するっていう目的」

かしのさん「最終的にはどこを目指している研究？」

鈴木「僕個人では、学習できればできるんでしょってとこにとどまらず、人間の知識を入れつつ、世界からいかに情報を獲得するかっていうバランス。
ある程度の事前知識を入れつつ世界から情報を獲得するってのがエージェントができるようになればいい。個人としては汎用的な人工知識を目指してる。」

佐藤さん「80 年代の AI、当時は Lisp や Prolog とかかちっとした仕組みで全部の常識をデータベース化して入れようって時代。そのひとつがスクリプトモデル。レストランだったらこういう会話するよねっていうスクリプトを全部入れて、、結局うまくいかなったが、かっちり全部決めると。ただその一方でファジィ理論もあってそれは制御の世界とかでうまくいった。ベイジアンに共感するのは、ふわっとした常識をデータベース化してディープモデルと組み合わせられるのかなと思う。それとちょっと overlap する部分もありそう」

鈴木「そう思う」

佐野さん「世界モデルの話を聞いていて思った。ゲームの世界だからデータはきれい。きれいなデータだから学習できた。シミュレータが作れた。それで強化学習できますってのはその通りだと思うが、実ロボットになったときどうなるんだろうというのが疑問。自動化されるかっていう部分も、ロボットだとセンサーの特性とか人手でやる部分も多くて、しばらく強化学習は時間かかるか」

須山「実世界での適用はすべて用意した上でちょっとやるかみたいな印象。。」

佐藤「デイビッドハーンの動画とか見てても思うんだけど、、強化学習なかなか実用できてなくて残念とは思うが、今まで微分可能なものだけやってたがそこを飛び越えようと思うと強化学習やらないと超えられないのでは」

須山「ベイズやってても思う。予測はいいけど、アクションが加わるとどうなるかとなるととたんに難しくなる」

### これからのデータサイエンスで必要なスキルは？

かしのさん「一般のリテラシーの底上げ。事業会社の人もデータサイエンスの知見を得るため。みんなプログラムやろうよ！と」

佐藤さん「普通のプログラマーにもベイズとか DL とかの知識を得てもらうことが重要。DB の B tree を DL で置き換えたらよくなったみたな話も聞いたことある。」

森賀「さっきのかしのさんの意見に近い。自分の会社はコンサル会社なのでクライアントにプロジェクトの要件を提案するんだが、データ分析で何を解決するかっていう正しい要件を作らないとプロジェクト初めてもPoCでおわっちゃったりとかが多かった。ちゃんと課題を設計する能力も大事。」

須山さん「ちゃんとしてないデータサイエンスのPJとは？」

森賀「システム実装まで考えてないなってやつとか」

須山さん「目標達成しても嬉しくないってこともあるよね。これを予測したいって言われてできますよって答えたりするんだけど、それ予測して何に使うのか決まってなかったり。真のゴールを見極めること」

佐藤「データサイエンス＋要件定義ですよね。顧客が本当に必要なものを聞き出す」

須山「MLOps的な話も関わってきますかね？」

藤原「機械学習屋に求められるものが多すぎてつらくなる。一人の人間になんでもかんでも求めるのは理想的じゃない。一人（機械学習屋）に集中しすぎない、スペシャリストたちが活躍する仕組みが必要ではないか」

### 個人的に勉強になった書籍・論文・ブログ・動画などは？

鈴木「機械学習はPRMLでやった。自分の頃はブログとかもあんまりなかった。論文とかは、D1の頃に深層生成モデルが出たので、論文読むときは原著論文を読んでる」

須山「僕もPRMLが最初だった。最初は 30% くらいしか理解できなかった。その次は 70% くらい。あと、この本もパーフェクトではなく、おかしいと思う部分もある。それくらいで読めばいい」

佐野（Hello Cyber）「僕もPRMLだった。独学でやろうとしてもきつかった。須山さんのブログ見つつ。ライブラリとかの実装をマネしながら実際に動かしてみるっていうのが一番の勉強かも。こう動くんだってところから数式が読めるようになるっていう順番もある」

かしの「David Mackay の Information Theory, Inference and Learning Algorithms」

佐藤「論文っていっぱい出過ぎてて追えない感じなんだけどどうしてる？」

かしの「松尾研のレビュー見てる」

鈴木「一人じゃ読めないので、みんなで読んだり、輪読したり、ツイッターでチェックしたり」

須山「論文多すぎじゃないか？」

鈴木「多すぎますね。読まなくていいものもけっこうあったりする。」

